{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Unzip"
      ],
      "metadata": {
        "id": "XWqT0T-QhtUW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmBr_N8ihri5",
        "outputId": "47864af8-4da4-44cc-f0dc-acfc44a8c39c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Localization_project-main.zip\n",
            "   creating: Localization_project-main/\n",
            "   creating: Localization_project-main/Ground/\n",
            "   creating: Localization_project-main/Ground/all_gt/\n",
            "  inflating: Localization_project-main/Ground/all_gt/1.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/10.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/11.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/12.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/13.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/14.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/15.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/16.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/17.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/18.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/19.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/2.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/20.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/21.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/22.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/23.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/24.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/25.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/26.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/27.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/28.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/29.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/3.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/30.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/31.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/32.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/33.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/34.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/35.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/36.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/37.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/38.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/39.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/4.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/40.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/41.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/42.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/43.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/44.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/45.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/46.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/47.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/48.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/49.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/5.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/50.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/6.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/7.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/8.csv  \n",
            "  inflating: Localization_project-main/Ground/all_gt/9.csv  \n",
            "  inflating: Localization_project-main/Ground/all_scan_sample.csv  \n",
            "   creating: Localization_project-main/Ground/beacons_pd/\n",
            "  inflating: Localization_project-main/Ground/data_sample_loc.csv  \n",
            "   creating: Localization_project-main/Ground/localization_results/\n",
            "  inflating: Localization_project-main/Ground/localization_results/knn_result_gt_predicted.csv  \n",
            "  inflating: Localization_project-main/Ground/localization_results/knn_result_pd_predicted.csv  \n",
            "   creating: Localization_project-main/Ground/results/\n",
            "  inflating: Localization_project-main/Ground/results/knn_result_gt_predicted.csv  \n",
            "  inflating: Localization_project-main/Ground/results/knn_result_pd_predicted.csv  \n",
            "  inflating: Localization_project-main/data_prep.py  \n",
            "  inflating: Localization_project-main/localization.py  \n",
            "  inflating: Localization_project-main/readme  \n",
            "  inflating: Localization_project-main/rssi_generation.py  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030182.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030183.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030184.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030185.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030186.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030187.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030193.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030276.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030277.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030278.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030279.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030280.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030281.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030282.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030283.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030284.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030285.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030288.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030289.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030290.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030291.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030292.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030293.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030294.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030295.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030296.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030297.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030298.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030300.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030301.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030302.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030303.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030304.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030305.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030306.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030307.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030308.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030310.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030311.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030312.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030313.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030314.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030315.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030316.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030319.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030321.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030328.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030336.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030337.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030913.csv  \n",
            "  inflating: Localization_project-main/Ground/beacons_gt/IW25030952.csv  \n",
            "   creating: Localization_project-main/First/beacons_gt/\n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030182_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030183_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030184_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030185_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030186_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030187_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030188_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030292_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030297_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030300_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030305_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030309_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030310_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030313_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030314_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030315_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030316_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030317_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030318_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030319_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030320_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030321_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030322_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030323_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030324_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030325_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030326_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030327_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030328_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030329_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030330_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030331_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030332_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030333_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030334_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030335_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030336_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030337_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030911_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030913_rssi.csv  \n",
            "  inflating: Localization_project-main/First/beacons_gt/IW25030926_rssi.csv  \n",
            "   creating: Localization_project-main/Second/beacons_gt/\n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030187_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030300_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030301_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030328_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030329_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030896_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030897_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030898_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030899_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030900_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030901_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030902_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030903_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030904_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030905_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030906_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030907_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030908_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030909_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030910_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030911_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030912_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030913_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030914_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030915_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030916_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030917_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030918_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030919_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030920_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030921_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030922_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030923_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030924_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030925_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030926_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030927_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030928_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030929_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030930_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030931_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030932_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030933_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030934_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030936_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030970_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030971_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030972_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030973_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030974_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030975_rssi.csv  \n",
            "  inflating: Localization_project-main/Second/beacons_gt/IW25030976_rssi.csv  \n",
            "   creating: Localization_project-main/Third/beacons_gt/\n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030185.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030193.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030300.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030301.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030905.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030906.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030907.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030922.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030937.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030938.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030939.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030940.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030941.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030942.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030943.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030944.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030945.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030946.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030947.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030948.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030949.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030950.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030952.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030953.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030954.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030955.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030956.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030957.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030958.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030959.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030960.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030961.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030962.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030971.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030972.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030973.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030974.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030975.csv  \n",
            "  inflating: Localization_project-main/Third/beacons_gt/IW25030976.csv  \n",
            "\u001b[0m\u001b[01;34mLocalization_project-main\u001b[0m/  Localization_project-main.zip  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "!unzip Localization_project-main.zip\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RSSI"
      ],
      "metadata": {
        "id": "R-IxqswciIEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import WhiteKernel, Kernel, Hyperparameter, RBF, ConstantKernel, RationalQuadratic, Matern, ExpSineSquared, DotProduct\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.spatial.distance import euclidean, cdist\n",
        "import scipy\n",
        "\n",
        "# Utility to split data into train and test sets\n",
        "def testAndTrainData(df1, df2):\n",
        "    tmp1 = df1['location'].to_numpy()\n",
        "    y1 = df1['rssi_mean']\n",
        "    y_train = y1.to_numpy()\n",
        "    X1 = [list(map(int, i.split(\",\"))) for i in tmp1]\n",
        "    X_train = np.array(X1)\n",
        "\n",
        "    tmp2 = df2['location'].to_numpy()\n",
        "    y2 = df2['rssi_mean']\n",
        "    y_test = y2.to_numpy()\n",
        "    X2 = [list(map(int, i.split(\",\"))) for i in tmp2]\n",
        "    X_test = np.array(X2)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\n",
        "# Epanechnikov kernel for GPR\n",
        "class EpanechnikovKernel(Kernel):\n",
        "    def __init__(self, length_scale=1.0, length_scale_bounds=(1e-5, 1e5)):\n",
        "        self.length_scale = length_scale\n",
        "        self.length_scale_bounds = length_scale_bounds\n",
        "\n",
        "    @property\n",
        "    def hyperparameter_length_scale(self):\n",
        "        return Hyperparameter(\"length_scale\", \"numeric\", self.length_scale_bounds)\n",
        "\n",
        "    def __call__(self, X, Y=None, eval_gradient=False):\n",
        "        X = np.atleast_2d(X)\n",
        "        length_scale = self.length_scale\n",
        "\n",
        "        if Y is None:\n",
        "            Y = X\n",
        "        else:\n",
        "            Y = np.atleast_2d(Y)\n",
        "\n",
        "        # Pairwise Euclidean distances\n",
        "        dists_sq = np.sum(X**2, axis=1)[:, np.newaxis] + \\\n",
        "                   np.sum(Y**2, axis=1)[np.newaxis, :] - \\\n",
        "                   2 * np.dot(X, Y.T)\n",
        "        dists = np.sqrt(np.maximum(dists_sq, 1e-12))\n",
        "        dists_normalized = dists / length_scale\n",
        "\n",
        "        # Epanechnikov kernel\n",
        "        K = (3 / 4) * np.maximum(1 - dists_normalized**2, 0)\n",
        "\n",
        "        if eval_gradient:\n",
        "            mask = (dists_normalized <= 1)\n",
        "            dK_dl = (3 / 4) * (2 * dists_normalized**2 / length_scale) * mask\n",
        "            return K, dK_dl[..., np.newaxis]\n",
        "        else:\n",
        "            return K\n",
        "\n",
        "    def diag(self, X):\n",
        "        return np.full(X.shape[0], 0.75)\n",
        "\n",
        "    def is_stationary(self):\n",
        "        return True\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"EpanechnikovKernel(length_scale={self.length_scale})\"\n",
        "\n",
        "def calculate_distances(X):\n",
        "    \"\"\"Calculate distances from origin and center for enhanced features\"\"\"\n",
        "    center = np.array([121.5, 130])  # Center of the grid (242x259)\n",
        "    distances = np.array([\n",
        "        [euclidean(point, [0, 0]), euclidean(point, center)]\n",
        "        for point in X\n",
        "    ])\n",
        "    return distances\n",
        "\n",
        "\n",
        "\n",
        "# Main processing loop\n",
        "floor = '/content/Localization_project-main/Ground'\n",
        "folder_path = floor + '/beacons_gt/'\n",
        "\n",
        "test_location = [\n",
        "    \"152, 92\", \"73, 164\", \"103, 80\", \"105, 51\", \"166, 106\", \"224, 124\",\n",
        "    \"43, 209\", \"184, 126\", \"238, 135\", \"113, 80\", \"70, 191\", \"140, 217\",\n",
        "    \"81, 18\", \"186, 250\", \"156, 134\", \"202, 181\", \"64, 164\", \"177, 159\",\n",
        "    \"116, 53\", \"105, 53\", \"116, 60\", \"152, 80\", \"132, 60\", \"132, 51\",\n",
        "    \"132, 70\", \"132, 80\", \"152, 51\", \"140, 80\", \"178, 96\", \"156, 118\",\n",
        "    \"178, 118\", \"116, 80\", \"152, 90\", \"147, 87\", \"150, 80\"\n",
        "]\n",
        "\n",
        "seasonal_kernel = (2.0 ** 2 * RBF(length_scale=100.0) * ExpSineSquared(length_scale=1.0, periodicity=1.0, periodicity_bounds=\"fixed\"))\n",
        "irregularities_kernel = 0.5 ** 2 * RationalQuadratic(length_scale=1.0, alpha=1.0)\n",
        "\n",
        "# Kernel candidates to test\n",
        "kernel_candidates = [\n",
        "     Matern(nu = 0.1) + EpanechnikovKernel(length_scale=1.0) + ConstantKernel(1.0, (1e-3, 1e3)) * WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 1e5)) + seasonal_kernel + irregularities_kernel,\n",
        "    Matern(nu = 1.1) + EpanechnikovKernel(length_scale=1.0) + ConstantKernel(1.0, (1e-3, 1e3)) * WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 1e5)) + seasonal_kernel + irregularities_kernel,\n",
        "    Matern(nu = 2.0) + EpanechnikovKernel(length_scale=1.0) + ConstantKernel(1.0, (1e-3, 1e3)) * WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 1e5)) + seasonal_kernel + irregularities_kernel,\n",
        "DotProduct() + Matern(nu=0.1) + ConstantKernel(1.0, (1e-3, 1e3)) * WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 1e5)) + seasonal_kernel + irregularities_kernel,\n",
        "    DotProduct() + ConstantKernel(1.0, (1e-3, 1e3)) * WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 1e5)) + seasonal_kernel + irregularities_kernel,\n",
        "  #   Matern(nu = 2.5) + EpanechnikovKernel(length_scale=1.0)\n",
        "  #   + ConstantKernel(1.0, (1e-3, 1e3)) * WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 1e5))\n",
        "  #   + seasonal_kernel + irregularities_kernel,\n",
        "  #   Matern(nu = 1.5) + EpanechnikovKernel(length_scale=1.0)\n",
        "  #   + ConstantKernel(1.0, (1e-3, 1e3)) * WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 1e5))\n",
        "  #   + seasonal_kernel + irregularities_kernel,\n",
        "  # DotProduct() + RBF(length_scale=1.0) + ConstantKernel(1.0, (1e-3, 1e3)) * WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 1e5))\n",
        "  #   + seasonal_kernel + irregularities_kernel,\n",
        "  #   DotProduct() + EpanechnikovKernel(length_scale=1.0)\n",
        "  #   + ConstantKernel(1.0, (1e-3, 1e3)) * WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 1e5))\n",
        "  #   + seasonal_kernel+ irregularities_kernel,\n",
        "  #   DotProduct() + Matern(nu=1.5) + ConstantKernel(1.0, (1e-3, 1e3)) * WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 1e5))\n",
        "  #   + seasonal_kernel + irregularities_kernel,\n",
        "  #   DotProduct() + Matern(nu=2.5) + ConstantKernel(1.0, (1e-3, 1e3)) * WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 1e5))\n",
        "  #   + seasonal_kernel + irregularities_kernel\n",
        "]\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    print(f\"Processing {filename}\")\n",
        "    if not filename.endswith('.csv'):\n",
        "        continue\n",
        "\n",
        "    # Load data\n",
        "    df = pd.read_csv(os.path.join(folder_path, filename))\n",
        "    v = filename.split('.csv')[0]\n",
        "\n",
        "    # Split data\n",
        "    df1 = df.loc[~df['location'].isin(test_location)]\n",
        "    df2 = df.loc[df['location'].isin(test_location)].sort_values(by=['location'])\n",
        "    X_train, y_train, X_test, y_test = testAndTrainData(df1, df2)\n",
        "\n",
        "    # Feature engineering: Add distance-based features\n",
        "    X_train_dist = calculate_distances(X_train)\n",
        "    X_test_dist = calculate_distances(X_test)\n",
        "\n",
        "    # Combine coordinates with distance features\n",
        "    X_train_extended = np.hstack((X_train, X_train_dist))\n",
        "    X_test_extended = np.hstack((X_test, X_test_dist))\n",
        "\n",
        "    # Scaling\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_extended)\n",
        "    X_test_scaled = scaler.transform(X_test_extended)\n",
        "\n",
        "    # Track best model for this beacon\n",
        "    best_mae = float('inf')\n",
        "    best_gp = None\n",
        "    best_kernel = None\n",
        "\n",
        "    # Try each kernel candidate\n",
        "    for kernel in kernel_candidates:\n",
        "        gp = GaussianProcessRegressor(\n",
        "            kernel=kernel,\n",
        "            n_restarts_optimizer=15,\n",
        "            normalize_y=True,\n",
        "            alpha=0.01  # Small noise for stability\n",
        "        )\n",
        "\n",
        "        # Fit and predict\n",
        "        gp.fit(X_train_scaled, y_train)\n",
        "        y_pred, _ = gp.predict(X_test_scaled, return_std=True)\n",
        "\n",
        "        # Calculate MAE\n",
        "        current_mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "        # Track best kernel\n",
        "        if current_mae < best_mae:\n",
        "            best_mae = current_mae\n",
        "            best_gp = gp\n",
        "            best_kernel = kernel\n",
        "\n",
        "    print(f\"Best kernel for {v}: {best_kernel} with MAE: {best_mae:.2f}\")\n",
        "\n",
        "    # ================== DYNAMIC MESHGRID GENERATION ==================\n",
        "    # Combine all data points to determine bounds\n",
        "    all_points = np.vstack((X_train, X_test))\n",
        "\n",
        "    # Get min/max coordinates with buffer\n",
        "    min_x, min_y = np.min(all_points, axis=0)\n",
        "    max_x, max_y = np.max(all_points, axis=0)\n",
        "\n",
        "    # Add 10% buffer to the bounding box\n",
        "    x_buffer = max(1, int(0.1 * (max_x - min_x)))\n",
        "    y_buffer = max(1, int(0.1 * (max_y - min_y)))\n",
        "\n",
        "    # Define bounds with buffer (clamped to 1-242/259 range)\n",
        "    min_x = max(1, min_x - x_buffer)\n",
        "    max_x = min(242, max_x + x_buffer)\n",
        "    min_y = max(1, min_y - y_buffer)\n",
        "    max_y = min(259, max_y + y_buffer)\n",
        "\n",
        "    # Create dynamic meshgrid within bounds\n",
        "    x1 = np.arange(min_x, max_x + 1).astype(int)\n",
        "    x2 = np.arange(min_y, max_y + 1).astype(int)\n",
        "    X0p, X1p = np.meshgrid(x1, x2)\n",
        "    grid_points = np.c_[X0p.ravel(), X1p.ravel()]\n",
        "\n",
        "    # Add distance features to grid points\n",
        "    grid_distances = calculate_distances(grid_points)\n",
        "    grid_points_extended = np.hstack((grid_points, grid_distances))\n",
        "    grid_points_scaled = scaler.transform(grid_points_extended)\n",
        "\n",
        "    # Predict using best model\n",
        "    mean_pred, std_pred = best_gp.predict(grid_points_scaled, return_std=True)\n",
        "\n",
        "    # Create full grid arrays with -99 default\n",
        "    full_x = np.arange(1, 243)  # 1-242\n",
        "    full_y = np.arange(1, 260)  # 1-259\n",
        "    full_X0p, full_X1p = np.meshgrid(full_x, full_y)\n",
        "    full_grid_points = np.c_[full_X0p.ravel(), full_X1p.ravel()]\n",
        "\n",
        "    # Initialize full RSSI arrays with -99\n",
        "    full_mean_pred = np.full(len(full_grid_points), -102.0)\n",
        "    full_std_pred = np.full(len(full_grid_points), -102.0)\n",
        "\n",
        "    # Create mapping from coordinate to index\n",
        "    coord_to_index = {(x, y): i for i, (x, y) in enumerate(full_grid_points)}\n",
        "\n",
        "    # Map predictions to full grid\n",
        "    for (x, y), mean_val, std_val in zip(grid_points, mean_pred, std_pred):\n",
        "        idx = coord_to_index.get((x, y), None)\n",
        "        if idx is not None:\n",
        "            full_mean_pred[idx] = mean_val\n",
        "            full_std_pred[idx] = std_val\n",
        "\n",
        "    # Prepare data for saving\n",
        "    data = [\n",
        "        [f\"{x}, {y}\", round(mean, 2), round(std, 2)]\n",
        "        for (x, y), mean, std in zip(full_grid_points, full_mean_pred, full_std_pred)\n",
        "    ]\n",
        "    # ================== END DYNAMIC MESHGRID ==================\n",
        "\n",
        "    df_out = pd.DataFrame(data, columns=[\"location\", \"rssi_mean\", \"rssi_std\"])\n",
        "    df_out.to_csv(f'/content/Localization_project-main/Ground/beacons_pd/{v}.csv', index=False)\n",
        "\n",
        "    # Final evaluation\n",
        "    y_pred, _ = best_gp.predict(X_test_scaled, return_std=True)\n",
        "    final_mae = mean_absolute_error(y_test, y_pred)\n",
        "    print(f\"  Final MAE: {final_mae:.2f}\")\n",
        "    print(f\"  Grid size: Original (242x259) | Dynamic: ({min_x}-{max_x})x({min_y}-{max_y})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7JMAovliJIa",
        "outputId": "7bd606cf-a1db-4153-8483-d8088e7532dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing IW25030290.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030290: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 1.39\n",
            "  Final MAE: 1.39\n",
            "  Grid size: Original (242x259) | Dynamic: (59-79)x(70-191)\n",
            "Processing IW25030183.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030183: Matern(length_scale=1, nu=1.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 3.43\n",
            "  Final MAE: 3.43\n",
            "  Grid size: Original (242x259) | Dynamic: (23-161)x(115-231)\n",
            "Processing IW25030321.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030321: Matern(length_scale=1, nu=1.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 4.60\n",
            "  Final MAE: 4.60\n",
            "  Grid size: Original (242x259) | Dynamic: (111-179)x(45-124)\n",
            "Processing IW25030294.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030294: DotProduct(sigma_0=1) + Matern(length_scale=1, nu=0.1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 0.96\n",
            "  Final MAE: 0.96\n",
            "  Grid size: Original (242x259) | Dynamic: (31-73)x(181-225)\n",
            "Processing IW25030952.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030952: DotProduct(sigma_0=1) + Matern(length_scale=1, nu=0.1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 0.32\n",
            "  Final MAE: 0.32\n",
            "  Grid size: Original (242x259) | Dynamic: (28-210)x(116-217)\n",
            "Processing IW25030316.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030316: DotProduct(sigma_0=1) + Matern(length_scale=1, nu=0.1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 6.05\n",
            "  Final MAE: 6.05\n",
            "  Grid size: Original (242x259) | Dynamic: (30-191)x(41-125)\n",
            "Processing IW25030298.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030298: Matern(length_scale=1, nu=1.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 0.54\n",
            "  Final MAE: 0.54\n",
            "  Grid size: Original (242x259) | Dynamic: (165-206)x(240-259)\n",
            "Processing IW25030303.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030303: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 4.12\n",
            "  Final MAE: 4.12\n",
            "  Grid size: Original (242x259) | Dynamic: (175-204)x(112-187)\n",
            "Processing IW25030283.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030283: DotProduct(sigma_0=1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 1.88\n",
            "  Final MAE: 1.88\n",
            "  Grid size: Original (242x259) | Dynamic: (9-125)x(79-94)\n",
            "Processing IW25030182.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030182: DotProduct(sigma_0=1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 1.93\n",
            "  Final MAE: 1.93\n",
            "  Grid size: Original (242x259) | Dynamic: (30-195)x(127-219)\n",
            "Processing IW25030184.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030184: DotProduct(sigma_0=1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 5.19\n",
            "  Final MAE: 5.19\n",
            "  Grid size: Original (242x259) | Dynamic: (28-210)x(178-220)\n",
            "Processing IW25030297.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030297: Matern(length_scale=1, nu=1.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 2.51\n",
            "  Final MAE: 2.51\n",
            "  Grid size: Original (242x259) | Dynamic: (161-206)x(240-259)\n",
            "Processing IW25030278.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030278: Matern(length_scale=1, nu=1.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 6.09\n",
            "  Final MAE: 6.09\n",
            "  Grid size: Original (242x259) | Dynamic: (5-165)x(45-83)\n",
            "Processing IW25030315.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030315: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 5.37\n",
            "  Final MAE: 5.37\n",
            "  Grid size: Original (242x259) | Dynamic: (83-186)x(45-124)\n",
            "Processing IW25030311.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030311: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 5.23\n",
            "  Final MAE: 5.23\n",
            "  Grid size: Original (242x259) | Dynamic: (120-198)x(41-169)\n",
            "Processing IW25030295.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030295: Matern(length_scale=1, nu=2) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 2.12\n",
            "  Final MAE: 2.12\n",
            "  Grid size: Original (242x259) | Dynamic: (38-195)x(213-259)\n",
            "Processing IW25030319.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030319: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 1.92\n",
            "  Final MAE: 1.92\n",
            "  Grid size: Original (242x259) | Dynamic: (124-154)x(47-96)\n",
            "Processing IW25030314.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030314: DotProduct(sigma_0=1) + Matern(length_scale=1, nu=0.1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 4.94\n",
            "  Final MAE: 4.94\n",
            "  Grid size: Original (242x259) | Dynamic: (98-185)x(45-124)\n",
            "Processing IW25030301.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030301: DotProduct(sigma_0=1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 2.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Final MAE: 2.63\n",
            "  Grid size: Original (242x259) | Dynamic: (24-242)x(112-259)\n",
            "Processing IW25030276.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030276: Matern(length_scale=1, nu=1.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 3.71\n",
            "  Final MAE: 3.71\n",
            "  Grid size: Original (242x259) | Dynamic: (59-121)x(47-83)\n",
            "Processing IW25030281.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030281: Matern(length_scale=1, nu=2) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 1.84\n",
            "  Final MAE: 1.84\n",
            "  Grid size: Original (242x259) | Dynamic: (9-125)x(23-113)\n",
            "Processing IW25030282.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030282: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 5.18\n",
            "  Final MAE: 5.18\n",
            "  Grid size: Original (242x259) | Dynamic: (9-125)x(73-161)\n",
            "Processing IW25030186.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030186: Matern(length_scale=1, nu=2) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 2.15\n",
            "  Final MAE: 2.15\n",
            "  Grid size: Original (242x259) | Dynamic: (28-210)x(126-225)\n",
            "Processing IW25030328.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030328: DotProduct(sigma_0=1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 0.01\n",
            "  Final MAE: 0.01\n",
            "  Grid size: Original (242x259) | Dynamic: (72-91)x(163-165)\n",
            "Processing IW25030285.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030285: Matern(length_scale=1, nu=2) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 0.88\n",
            "  Final MAE: 0.88\n",
            "  Grid size: Original (242x259) | Dynamic: (1-112)x(79-91)\n",
            "Processing IW25030336.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030336: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 2.00\n",
            "  Final MAE: 2.00\n",
            "  Grid size: Original (242x259) | Dynamic: (69-71)x(190-200)\n",
            "Processing IW25030280.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030280: DotProduct(sigma_0=1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 8.62\n",
            "  Final MAE: 8.62\n",
            "  Grid size: Original (242x259) | Dynamic: (78-119)x(38-71)\n",
            "Processing IW25030288.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030288: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 2.29\n",
            "  Final MAE: 2.29\n",
            "  Grid size: Original (242x259) | Dynamic: (58-83)x(70-191)\n",
            "Processing IW25030300.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030300: Matern(length_scale=1, nu=1.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 6.22\n",
            "  Final MAE: 6.22\n",
            "  Grid size: Original (242x259) | Dynamic: (24-242)x(85-259)\n",
            "Processing IW25030293.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030293: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 1.00\n",
            "  Final MAE: 1.00\n",
            "  Grid size: Original (242x259) | Dynamic: (58-82)x(92-192)\n",
            "Processing IW25030306.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030306: DotProduct(sigma_0=1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 2.67\n",
            "  Final MAE: 2.67\n",
            "  Grid size: Original (242x259) | Dynamic: (223-242)x(122-147)\n",
            "Processing IW25030296.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030296: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 7.88\n",
            "  Final MAE: 7.88\n",
            "  Grid size: Original (242x259) | Dynamic: (157-207)x(213-259)\n",
            "Processing IW25030187.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030187: DotProduct(sigma_0=1) + Matern(length_scale=1, nu=0.1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 1.34\n",
            "  Final MAE: 1.34\n",
            "  Grid size: Original (242x259) | Dynamic: (230-239)x(123-136)\n",
            "Processing IW25030291.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030291: Matern(length_scale=1, nu=1.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 2.17\n",
            "  Final MAE: 2.17\n",
            "  Grid size: Original (242x259) | Dynamic: (57-93)x(92-192)\n",
            "Processing IW25030305.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030305: DotProduct(sigma_0=1) + Matern(length_scale=1, nu=0.1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 3.63\n",
            "  Final MAE: 3.63\n",
            "  Grid size: Original (242x259) | Dynamic: (178-242)x(116-147)\n",
            "Processing IW25030337.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030337: Matern(length_scale=1, nu=1.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 1.56\n",
            "  Final MAE: 1.56\n",
            "  Grid size: Original (242x259) | Dynamic: (41-72)x(181-225)\n",
            "Processing IW25030279.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030279: DotProduct(sigma_0=1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 4.98\n",
            "  Final MAE: 4.98\n",
            "  Grid size: Original (242x259) | Dynamic: (90-146)x(42-72)\n",
            "Processing IW25030193.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030193: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 0.87\n",
            "  Final MAE: 0.87\n",
            "  Grid size: Original (242x259) | Dynamic: (32-167)x(116-220)\n",
            "Processing IW25030913.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030913: Matern(length_scale=1, nu=2) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 3.52\n",
            "  Final MAE: 3.52\n",
            "  Grid size: Original (242x259) | Dynamic: (28-210)x(116-220)\n",
            "Processing IW25030292.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030292: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 4.04\n",
            "  Final MAE: 4.04\n",
            "  Grid size: Original (242x259) | Dynamic: (62-92)x(101-191)\n",
            "Processing IW25030284.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030284: Matern(length_scale=1, nu=1.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 4.43\n",
            "  Final MAE: 4.43\n",
            "  Grid size: Original (242x259) | Dynamic: (1-123)x(79-81)\n",
            "Processing IW25030304.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030304: Matern(length_scale=1, nu=2) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 3.97\n",
            "  Final MAE: 3.97\n",
            "  Grid size: Original (242x259) | Dynamic: (148-242)x(114-163)\n",
            "Processing IW25030310.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030310: Matern(length_scale=1, nu=2) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 2.84\n",
            "  Final MAE: 2.84\n",
            "  Grid size: Original (242x259) | Dynamic: (92-229)x(41-169)\n",
            "Processing IW25030277.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030277: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 6.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Final MAE: 6.05\n",
            "  Grid size: Original (242x259) | Dynamic: (9-125)x(57-96)\n",
            "Processing IW25030308.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030308: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 4.63\n",
            "  Final MAE: 4.63\n",
            "  Grid size: Original (242x259) | Dynamic: (121-190)x(73-166)\n",
            "Processing IW25030185.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030185: DotProduct(sigma_0=1) + Matern(length_scale=1, nu=0.1) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 1.82\n",
            "  Final MAE: 1.82\n",
            "  Grid size: Original (242x259) | Dynamic: (25-242)x(181-220)\n",
            "Processing IW25030312.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030312: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 4.41\n",
            "  Final MAE: 4.41\n",
            "  Grid size: Original (242x259) | Dynamic: (154-185)x(89-120)\n",
            "Processing IW25030289.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030289: Matern(length_scale=1, nu=0.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 1.69\n",
            "  Final MAE: 1.69\n",
            "  Grid size: Original (242x259) | Dynamic: (59-79)x(70-191)\n",
            "Processing IW25030302.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030302: Matern(length_scale=1, nu=1.1) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 5.52\n",
            "  Final MAE: 5.52\n",
            "  Grid size: Original (242x259) | Dynamic: (175-204)x(139-195)\n",
            "Processing IW25030313.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k1__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__k2__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030313: Matern(length_scale=1, nu=2) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 4.76\n",
            "  Final MAE: 4.76\n",
            "  Grid size: Original (242x259) | Dynamic: (96-185)x(41-125)\n",
            "Processing IW25030307.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kernel for IW25030307: Matern(length_scale=1, nu=2) + EpanechnikovKernel(length_scale=1.0) + 1**2 * WhiteKernel(noise_level=0.1) + 2**2 * RBF(length_scale=100) * ExpSineSquared(length_scale=1, periodicity=1) + 0.5**2 * RationalQuadratic(alpha=1, length_scale=1) with MAE: 4.19\n",
            "  Final MAE: 4.19\n",
            "  Grid size: Original (242x259) | Dynamic: (117-227)x(41-169)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Localization_2"
      ],
      "metadata": {
        "id": "D-GRrDT3zesJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "import os\n",
        "from IPython.display import display\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C,WhiteKernel , RationalQuadratic ,ExpSineSquared\n",
        "# %matplotlib notebook\n",
        "\n",
        "\n",
        "# Directory containing beacon files\n",
        "def GroundTruthData(directory_gt, floor,test_location,num_files):\n",
        "\n",
        "    # Initialize an empty list to hold dataframes\n",
        "    dataframes_gt = []\n",
        "    # Loop through each beacon file\n",
        "    for filename in os.listdir(directory_gt):\n",
        "        # print(filename)\n",
        "        file_path = os.path.join(directory_gt, filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "        df.rename(columns={'rssi_mean':  filename.split('.csv')[0]}, inplace=True)\n",
        "        #df = df.drop(['rssi_std'], axis=1) # Drop 'rssi_std' column\n",
        "        dataframes_gt.append(df)  # Append dataframe to the list\n",
        "\n",
        "    dataframe_gt = pd.concat([df.set_index('location') for df in dataframes_gt], axis=1, join='outer').reset_index()\n",
        "    dataframe_gt.fillna('-97.7', inplace=True)\n",
        "    # print(dataframe_gt.round(0))\n",
        "    dataframe_gt.to_csv(floor+'/all_scan_sample.csv', index=False)\n",
        "\n",
        "    ### Randomly sampled 6 test location out of total 29 location and 3 outlier = 32 points####\n",
        "    test_data = dataframe_gt.loc[dataframe_gt['location'].isin(test_location)]\n",
        "    test_data = test_data.sort_values(by=['location'])\n",
        "    temp = test_data.location.str.split(\",\", n = -1, expand = True)\n",
        "    # print(dataframe_gt)\n",
        "    test_data['cordX'] = temp[0].astype(int)\n",
        "    test_data['cordY'] = temp[1].astype(int)\n",
        "    # print(data.head())\n",
        "    X_gt= test_data.iloc[:, 1:num_files]\n",
        "    y1_gt = test_data['cordX']\n",
        "    y2_gt = test_data['cordY']\n",
        "    test_data.head()\n",
        "    test_data.shape\n",
        "\n",
        "    return X_gt, y1_gt, y2_gt\n",
        "\n",
        "\n",
        "def Custom_PD_data(directory_pd, floor,test_location,num_files):\n",
        "\n",
        "    # Initialize an empty list to hold dataframes\n",
        "    dataframes_pd = []\n",
        "    # Loop through each beacon file\n",
        "    for filename in os.listdir(directory_pd):\n",
        "        # print(filename)\n",
        "        file_path = os.path.join(directory_pd, filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "        df.rename(columns={'rssi_mean':  filename.split('.csv')[0]}, inplace=True)\n",
        "        df = df.drop(['rssi_std'], axis=1) # Drop 'rssi_std' column\n",
        "        dataframes_pd.append(df)  # Append dataframe to the list\n",
        "\n",
        "    dataframe_pd = pd.concat([df.set_index('location') for df in dataframes_pd], axis=1, join='inner').reset_index()\n",
        "\n",
        "    ### Randomly sampled 6 test location out of total 29 location and 3 outlier = 32 points####\n",
        "    test_data = dataframe_pd.loc[dataframe_pd['location'].isin(test_location)]\n",
        "    test_data = test_data.sort_values(by=['location'])\n",
        "    temp = test_data.location.str.split(\",\", n = -1, expand = True)\n",
        "    test_data['cordX'] = temp[0].astype(int)\n",
        "    test_data['cordY'] = temp[1].astype(int)\n",
        "    # print(data.head())\n",
        "    X_pd_custom= test_data.iloc[:, 1:num_files]\n",
        "    y1_pd_custom = test_data['cordX']\n",
        "    y2_pd_custom = test_data['cordY']\n",
        "    test_data.head()\n",
        "    test_data.shape\n",
        "\n",
        "    return X_pd_custom, y1_pd_custom, y2_pd_custom\n",
        "\n",
        "### beacons_pd folder include predicted beacons rssi data ########\n",
        "def GPPredictedData(directory_pd, num_files):\n",
        "    dataframes_pd = []\n",
        "    for filename in os.listdir(directory_pd):\n",
        "        file_path = os.path.join(directory_pd, filename)\n",
        "        # Read CSV file\n",
        "        df = pd.read_csv(file_path)\n",
        "        # Rename column\n",
        "        df.rename(columns={'rssi_mean':  filename.split('.csv')[0]}, inplace=True)\n",
        "        # Drop 'rssi_std' column\n",
        "        df = df.drop(['rssi_std'], axis=1)\n",
        "        # Append dataframe to the list\n",
        "        dataframes_pd.append(df)\n",
        "    # Merge all dataframes on 'location'\n",
        "    dataframes_pd = pd.concat([df.set_index('location') for df in dataframes_pd], axis=1, join='inner').reset_index()\n",
        "    new = dataframes_pd.location.str.split(\",\", n = -1, expand = True)\n",
        "    dataframes_pd['cordX'] = new[0].astype(int)\n",
        "    dataframes_pd['cordY'] = new[1].astype(int)\n",
        "    X_pd = dataframes_pd.iloc[:, 1:num_files]\n",
        "    y1_pd = dataframes_pd['cordX']\n",
        "    y2_pd = dataframes_pd['cordY']\n",
        "\n",
        "    dataframes_pd.head()\n",
        "    dataframes_pd.shape\n",
        "\n",
        "    return X_pd, y1_pd, y2_pd\n",
        "\n",
        "\n",
        "def ContinuousData(directory_pd, num_files):\n",
        "    dataframes_pd = []\n",
        "\n",
        "        # Read CSV file\n",
        "    dataframes_pd = pd.read_csv(file_path)\n",
        "        # Rename column\n",
        "\n",
        "    # Merge all dataframes on 'location'\n",
        "    #dataframes_pd = pd.concat([df.set_index('location') for df in dataframes_pd], axis=1, join='inner').reset_index()\n",
        "    new = dataframes_pd.location.str.split(\",\", n = -1, expand = True)\n",
        "    dataframes_pd['cordX'] = new[0].astype(int)\n",
        "    dataframes_pd['cordY'] = new[1].astype(int)\n",
        "    X_cd = dataframes_pd.iloc[:, 1:num_files]\n",
        "    y1_cd = dataframes_pd['cordX']\n",
        "    y2_cd = dataframes_pd['cordY']\n",
        "\n",
        "    dataframes_pd.head()\n",
        "    dataframes_pd.shape\n",
        "\n",
        "    return X_cd, y1_cd, y2_cd\n",
        "\n",
        "#################### KNN training for X-axis ####################\n",
        "def knnXaxis(X_train, y1_train, X_test,y1_test, y1_gt):\n",
        "    print(\"---------KNN training for X-axis result---------\" )\n",
        "    # print(X_test, y1_test)\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors = 3)\n",
        "    # print(X_train, y1_train)\n",
        "    knn_classifier.fit(X_train, y1_train.values.ravel())\n",
        "    # test using GP predicted test dataset\n",
        "    #y1_pred=knn_classifier.predict(X_test)\n",
        "    y1_pred_custom=knn_classifier.predict(X_pd_custom)\n",
        "    # print(y1_pred_custom)\n",
        "    # print(y1_pd_custom)\n",
        "    # knn_accuracy=accuracy_score(y1_test, y1_pred)\n",
        "    # print('\\nThe Models Accuracy is', knn_accuracy)\n",
        "    MAE1 = mean_absolute_error(y1_pred,y1_test)\n",
        "    MAE2 = mean_absolute_error(y1_pred_custom,y1_pd_custom)\n",
        "    print(\"Predicted data knn-mae-X-axis :\\t\",MAE1*0.305, \"m\")\n",
        "    print(\"Custom Predicted data knn-mae-X-axis (0 to 15 ft):\\t\",MAE2*0.305, \"m\")\n",
        "    # test using ground truth test dataset\n",
        "    # print(\"Inputs==========\",X_gt)\n",
        "    y1_pred_gt=knn_classifier.predict(X_gt)\n",
        "    # print(\"Outputs======\",y1_pred_gt)\n",
        "    # # knn_accuracy=accuracy_score(y1_gt, y1_pred_gt)\n",
        "    # # print('\\nThe Models Accuracy for ground truth values, is', knn_accuracy)\n",
        "    # print(y1_gt,y1_pred_gt)\n",
        "    MAE3 = mean_absolute_error(y1_pred_gt,y1_gt)\n",
        "    #print(\"Ground truth data knn-mae-X-axis :\\t\",MAE3*0.305, \"m\")\n",
        "\n",
        "    return MAE1, MAE2, MAE3, y1_pred, y1_pred_custom, y1_pred_gt\n",
        "\n",
        "\n",
        "#################### KNN training for Y-axis ####################\n",
        "def knnYaxis(X_train, y2_train, X_test, y2_test,y2_gt):\n",
        "    print(\"---------KNN training for Y-axis result---------\" )\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors = 3)\n",
        "    knn_classifier.fit(X_train, y2_train.values.ravel())\n",
        "    # test using GP predicted test dataset\n",
        "    y2_pred=knn_classifier.predict(X_test)\n",
        "    y2_pred_custom=knn_classifier.predict(X_pd_custom)\n",
        "    #print(y2_pred)\n",
        "    # knn_accuracy=accuracy_score(y2_test, y2_pred)\n",
        "    # print('\\nThe Models Accuracy is', knn_accuracy)\n",
        "\n",
        "    MAE4 = mean_absolute_error(y2_pred,y2_test)\n",
        "    MAE5 = mean_absolute_error(y2_pred_custom,y2_pd_custom)\n",
        "    print(\"Predicted data knn-mae-Y-axis :\\t\",MAE4*0.305, \"m\")\n",
        "    print(\"Custom Predicted data knn-mae-Y-axis (0 to 15 ft):\\t\",MAE5*0.305, \"m\")\n",
        "    # test using ground truth test dataset\n",
        "    y2_pred_gt=knn_classifier.predict(X_gt)\n",
        "    MAE6 = mean_absolute_error(y2_pred_gt,y2_gt)\n",
        "    # print(y2_gt,y2_pred_gt)\n",
        "    #print(\"Ground truth data knn-mae-Y-axis :\\t\",MAE6*0.305, \"m\")\n",
        "\n",
        "    return MAE4, MAE5, MAE6, y2_pred, y2_pred_custom, y2_pred_gt\n",
        "\n",
        "\n",
        "########## KNN - Localization performance #########################\n",
        "########### Part 1: Result on GP predicted test dataset ##################\n",
        "def knnLocalizationPredictedData(y1_test, y2_test, X_test, y1_pred, y2_pred, path_3):\n",
        "    r1 = pd.concat([y1_test, y2_test, X_test], axis=1)\n",
        "    # r1.rename(columns={'cordX': 'cordXold', 1: 'cordYold'}, inplace=True)\n",
        "    # r1.drop(columns=[\"cordX\", \"cordY\"], inplace=True)\n",
        "    r2 = pd.concat([pd.DataFrame({'SP_cordX':y1_pred}),pd.DataFrame({'SP_cordY':y2_pred})], axis=1)\n",
        "    result = pd.concat([r1,r2.set_index(r1.index)], axis=1)\n",
        "    #display(result)\n",
        "    # euclidean distance error in a grid world\n",
        "    # result = result.rename(columns={0: 'cordXold', 1: 'cordYold'}, inplace=True)\n",
        "    result['dist_localization_error_pd']  = np.round(np.sqrt((result['cordX'] - result['SP_cordX'])**2 + (result['cordY'] - result['SP_cordY'])**2),2)\n",
        "    result['loc'] = (result['cordX'].map(str)).str.cat(result['cordY'].map(str),sep=\",\")\n",
        "    result['Pred_loc'] = (result['SP_cordX'].map(str)).str.cat(result['SP_cordY'].map(str),sep=\",\")\n",
        "    result = result[['loc','Pred_loc','dist_localization_error_pd']]\n",
        "    # print(\"Part 1: Result on GP predicted test dataset ==========\")\n",
        "\n",
        "    print(\"Localziation_mse_knn_pd_predicted\", np.mean(result['dist_localization_error_pd'])*0.305, \"m\")\n",
        "    # print(\"Localization error WRT Predicted data\", result['dist_localization_error_pd']*0.305, \"m\")\n",
        "    #result.to_csv(path_3+'/knn_result_pd_predicted.csv', index=False)\n",
        "\n",
        "    return np.mean(result['dist_localization_error_pd'])\n",
        "\n",
        "\n",
        "def knnLocalizationcustomPD(y1_pd_custom, y2_pd_custom, X_pd_custom, y1_pred_custom, y2_pred_custom):\n",
        "    r1 = pd.concat([y1_pd_custom, y2_pd_custom, X_pd_custom], axis=1)\n",
        "    # r1.rename(columns={'cordX': 'cordXold', 1: 'cordYold'}, inplace=True)\n",
        "    # r1.drop(columns=[\"cordX\", \"cordY\"], inplace=True)\n",
        "    r2 = pd.concat([pd.DataFrame({'SP_cordX':y1_pred_custom}),pd.DataFrame({'SP_cordY':y2_pred_custom})], axis=1)\n",
        "    result = pd.concat([r1,r2.set_index(r1.index)], axis=1)\n",
        "    #display(result)\n",
        "    # euclidean distance error in a grid world\n",
        "    # result = result.rename(columns={0: 'cordXold', 1: 'cordYold'}, inplace=True)\n",
        "    result['dist_localization_error_pd']  = np.round(np.sqrt((result['cordX'] - result['SP_cordX'])**2 + (result['cordY'] - result['SP_cordY'])**2),2)\n",
        "    result['loc'] = (result['cordX'].map(str)).str.cat(result['cordY'].map(str),sep=\",\")\n",
        "    result['Pred_loc'] = (result['SP_cordX'].map(str)).str.cat(result['SP_cordY'].map(str),sep=\",\")\n",
        "    result = result[['loc','Pred_loc','dist_localization_error_pd']]\n",
        "    # print(\"Part 1: Result on GP predicted test dataset ==========\")\n",
        "\n",
        "    print(\"Localziation_mse_knn_custom_pd_predicted (0 to 15 ft)\", np.mean(result['dist_localization_error_pd'])*0.305, \"m\")\n",
        "    # print(\"Localization error WRT Predicted data\", result['dist_localization_error_pd']*0.305, \"m\")\n",
        "    #result.to_csv(path_3+'/knn_result_pd_predicted.csv', index=False)\n",
        "\n",
        "    return np.mean(result['dist_localization_error_pd'])\n",
        "\n",
        "\n",
        "\n",
        "########## Part 2: Result on Ground truth test dataset ###################\n",
        "def knnLocalizationGroundTruthData(y1_gt, y2_gt, X_gt, y1_pred_gt, y2_pred_gt, path_4):\n",
        "    r1 = pd.concat([y1_gt, y2_gt, X_gt], axis=1)\n",
        "    r2 = pd.concat([pd.DataFrame({'GPP_cordX':y1_pred_gt}),pd.DataFrame({'GPP_cordY':y2_pred_gt})], axis=1)\n",
        "    result = pd.concat([r1,r2.set_index(r1.index)], axis=1)\n",
        "    #print(result)\n",
        "    # euclidean distance error in a grid world\n",
        "    result['dist_localization_error_gt']  = np.round(np.sqrt((result['cordX'] - result['GPP_cordX'])**2 + (result['cordY'] - result['GPP_cordY'])**2),2)\n",
        "    result['loc'] = (result['cordX'].map(str)).str.cat(result['cordY'].map(str),sep=\",\")\n",
        "    result['Pred_loc'] = (result['GPP_cordX'].map(str)).str.cat(result['GPP_cordY'].map(str),sep=\",\")\n",
        "    result = result[['loc','Pred_loc','dist_localization_error_gt']]\n",
        "    # print(\"Part 2: Result on Ground truth test dataset ==========\")\n",
        "\n",
        "    print(\"Localziation_mse_knn_gt_predicted\", np.mean(result['dist_localization_error_gt'])*0.305, \"m\")\n",
        "    # print(\"Localization error WRT Ground truth data\", result['dist_localization_error_gt']*0.305, \"m\")\n",
        "    #result.to_csv(path_4+'/knn_result_gt_predicted.csv', index=False)\n",
        "\n",
        "    return np.mean(result['dist_localization_error_gt'])\n",
        "\n",
        "\n",
        "floor = '/content/Localization_project-main/Ground'\n",
        "path_1 ='/content/Localization_project-main/Ground/beacons_gt'\n",
        "\n",
        "test_location_pd = [\n",
        "    \"167, 242\", \"197, 185\", \"78, 70\", \"133, 63\", \"153, 111\", \"170, 230\", \"63, 147\", \"205, 244\", \"79, 76\", \"157, 117\", \"152, 121\", \"185, 200\", \"42, 219\", \"92, 217\", \"165, 107\", \"173, 153\", \"61, 100\", \"194, 114\", \"155, 89\", \"120, 77\", \"129, 49\", \"189, 166\", \"48, 217\", \"244, 228\", \"69, 179\", \"109, 216\", \"172, 113\", \"151, 120\", \"87, 79\", \"157, 80\", \"189, 170\", \"38, 222\", \"154, 134\", \"76, 152\", \"190, 238\", \"244, 233\", \"84, 156\", \"56, 98\", \"69, 112\", \"164, 249\", \"87, 218\", \"47, 83\", \"82, 60\", \"157, 191\", \"174, 222\", \"189, 119\", \"205, 175\", \"69, 158\", \"203, 221\", \"116, 49\", \"177, 136\", \"174, 215\", \"249, 138\", \"150, 66\", \"159, 194\", \"172, 114\", \"225, 120\", \"123, 220\", \"68, 115\", \"91, 78\", \"39, 220\", \"79, 32\", \"15, 79\", \"54, 78\", \"180, 199\", \"56, 79\", \"195, 212\", \"195, 239\", \"210, 117\", \"133, 66\", \"181, 242\", \"83, 63\", \"196, 188\", \"220, 210\", \"236, 144\", \"84, 151\", \"88, 158\", \"84, 18\", \"175, 214\", \"137, 216\", \"234, 125\", \"72, 151\", \"82, 59\", \"154, 84\", \"125, 217\", \"222, 205\", \"202, 218\", \"203, 175\", \"107, 216\", \"169, 258\", \"191, 215\", \"47, 80\", \"148, 49\", \"167, 228\", \"46, 218\", \"165, 93\", \"240, 125\", \"172, 153\", \"225, 216\", \"237, 148\",\n",
        "    \"69, 224\", \"190, 233\", \"86, 226\", \"226, 118\", \"249, 147\", \"202, 191\", \"182, 181\", \"197, 110\", \"124, 63\", \"145, 214\", \"86, 35\", \"90, 212\", \"2, 90\", \"59, 175\", \"211, 180\", \"189, 87\", \"38, 192\", \"165, 130\", \"74, 207\", \"240, 116\", \"74, 116\", \"147, 49\", \"106, 38\", \"161, 83\", \"27, 88\", \"163, 195\", \"202, 212\", \"155, 213\", \"78, 24\", \"126, 50\", \"190, 160\", \"76, 206\", \"76, 53\", \"56, 226\", \"69, 222\", \"175, 252\", \"144, 121\", \"145, 50\", \"190, 196\", \"123, 57\", \"190, 180\", \"77, 23\", \"93, 149\", \"216, 220\", \"66, 224\", \"89, 60\", \"55, 120\", \"86, 37\", \"165, 195\", \"123, 49\", \"96, 224\", \"73, 47\", \"154, 183\", \"244, 208\", \"17, 71\", \"147, 73\", \"231, 150\", \"48, 191\", \"99, 68\", \"188, 182\", \"193, 168\", \"217, 128\", \"205, 240\", \"76, 29\", \"174, 228\", \"185, 112\", \"182, 148\", \"76, 72\", \"127, 43\", \"194, 166\", \"137, 74\", \"73, 205\", \"62, 180\", \"148, 188\", \"164, 126\", \"187, 188\", \"51, 74\", \"233, 219\", \"190, 185\", \"122, 56\", \"120, 86\", \"23, 84\", \"155, 139\", \"98, 81\", \"74, 113\", \"112, 88\", \"190, 203\", \"59, 142\", \"147, 136\", \"211, 127\", \"93, 224\", \"128, 42\", \"200, 192\", \"60, 176\", \"71, 219\", \"33, 208\", \"70, 114\", \"85, 44\", \"183, 154\", \"70, 224\",\n",
        "    \"99, 157\", \"177, 82\", \"139, 130\", \"81, 92\", \"178, 181\", \"113, 34\", \"139, 127\", \"92, 43\", \"54, 170\", \"100, 154\", \"53, 90\", \"63, 228\", \"207, 190\", \"147, 40\", \"118, 228\", \"245, 205\", \"123, 227\", \"206, 205\", \"100, 156\", \"54, 198\", \"52, 153\", \"211, 190\", \"158, 181\", \"77, 207\", \"230, 233\", \"144, 113\", \"160, 207\", \"196, 108\", \"3, 70\", \"143, 134\", \"33, 229\", \"84, 229\", \"241, 114\", \"157, 206\", \"238, 240\", \"243, 115\", \"144, 43\", \"176, 180\", \"144, 106\", \"80, 109\", \"179, 175\", \"165, 147\", \"175, 83\", \"146, 194\", \"141, 117\", \"220, 196\", \"226, 196\", \"234, 112\", \"103, 206\", \"111, 205\", \"114, 34\", \"168, 196\", \"152, 39\", \"50, 103\", \"168, 186\", \"240, 155\", \"71, 67\", \"164, 67\", \"139, 228\", \"31, 206\", \"187, 230\", \"69, 27\", \"139, 96\", \"168, 85\", \"61, 229\", \"121, 226\", \"173, 84\", \"31, 207\", \"215, 176\", \"206, 192\", \"23, 223\", \"54, 109\", \"76, 140\", \"175, 173\", \"212, 203\", \"76, 118\", \"166, 141\", \"200, 164\", \"60, 193\", \"22, 220\", \"82, 90\", \"208, 165\", \"151, 144\", \"71, 54\", \"28, 207\", \"98, 146\", \"167, 128\", \"75, 120\", \"187, 151\", \"56, 229\", \"54, 126\", \"26, 92\", \"49, 101\", \"221, 135\", \"204, 227\", \"214, 206\", \"172, 187\", \"81, 102\", \"144, 138\", \"21, 69\"\n",
        "]\n",
        "test_location_ground = [\"152, 92\", \"116, 53\", \"105, 53\", \"116, 60\", \"152, 80\", \"132, 60\",\n",
        "    \"132, 51\", \"132, 70\", \"132, 80\", \"152, 51\", \"140, 80\", \"166, 106\",\n",
        "    \"178, 96\", \"156, 118\", \"178, 118\", \"116, 80\", \"152, 90\", \"147, 87\",\n",
        "    \"150, 80\", \"152, 70\", \"152, 60\", \"142, 57\", \"132, 57\", \"126, 80\",\n",
        "    \"113, 80\", \"116, 70\", \"110, 53\", \"105, 51\", \"176, 118\", \"174, 114\",\n",
        "    \"178, 106\", \"166, 118\", \"163, 111\", \"156, 108\", \"156, 98\", \"168, 96\",\n",
        "    \"174, 100\", \"163, 103\", \"167, 107\", \"183, 91\", \"150, 124\", \"177, 159\",\n",
        "    \"177, 133\", \"185, 125\", \"184, 126\", \"192, 118\", \"218, 118\", \"202, 118\",\n",
        "    \"212, 118\", \"177, 143\", \"177, 153\", \"93, 80\", \"103, 80\", \"91, 80\",\n",
        "    \"43, 80\", \"110, 48\", \"73, 164\", \"64, 106\", \"70, 108\", \"88, 154\",\n",
        "    \"70, 171\", \"64, 164\", \"64, 154\", \"64, 171\", \"64, 133\", \"90, 164\",\n",
        "    \"60, 100\", \"70, 184\", \"64, 100\", \"64, 118\", \"64, 128\", \"64, 143\",\n",
        "    \"64, 153\", \"68, 154\", \"78, 154\", \"64, 160\", \"70, 181\", \"80, 164\",\n",
        "    \"80, 174\", \"81, 80\", \"64, 80\", \"74, 80\", \"64, 93\", \"18, 80\", \"93, 69\",\n",
        "    \"54, 80\", \"47, 80\", \"33, 80\", \"81, 50\", \"81, 60\", \"81, 70\", \"81, 30\",\n",
        "    \"28, 80\", \"156, 134\", \"156, 191\", \"182, 191\", \"195, 191\", \"70, 191\",\n",
        "    \"70, 199\", \"43, 199\", \"43, 212\", \"43, 209\", \"66, 217\", \"96, 217\",\n",
        "    \"9, 80\", \"9, 90\", \"94, 53\", \"110, 44\", \"95, 53\", \"81, 40\", \"231, 131\",\n",
        "    \"238, 124\", \"238, 135\", \"238, 145\", \"224, 124\", \"195, 199\", \"182, 199\",\n",
        "    \"195, 181\", \"202, 181\", \"170, 217\", \"168, 246\", \"168, 253\", \"203, 246\",\n",
        "    \"182, 217\", \"195, 217\", \"203, 217\", \"224, 208\", \"242, 229\", \"242, 217\",\n",
        "    \"224, 217\", \"184, 166\", \"191, 173\", \"202, 176\", \"172, 217\", \"170, 224\",\n",
        "    \"170, 234\", \"164, 253\", \"166, 257\", \"202, 246\", \"161, 217\", \"56, 217\",\n",
        "    \"86, 217\", \"106, 217\", \"116, 217\", \"126, 217\", \"136, 217\", \"140, 217\",\n",
        "    \"192, 241\", \"43, 222\", \"43, 217\", \"34, 217\", \"249, 135\", \"242, 145\",\n",
        "    \"51, 217\", \"151, 220\", \"76, 217\", \"81, 18\", \"186, 246\", \"186, 250\",\n",
        "    \"192, 246\", \"180, 246\", \"186, 259\"]\n",
        "\n",
        "num_files = len(os.listdir(path_1))+1    # Count the number of files\n",
        "test_location = test_location_ground\n",
        "\n",
        "\n",
        "#print(test_location)\n",
        "X_gt, y1_gt, y2_gt = GroundTruthData(path_1, floor, test_location,num_files)\n",
        "\n",
        "path_2 = '/content/Localization_project-main/Ground/beacons_pd'\n",
        "num_files = len(os.listdir(path_2))+1    # Count the number of files\n",
        "X_pd_custom, y1_pd_custom, y2_pd_custom = Custom_PD_data(path_2,floor,test_location_pd,num_files)\n",
        "X_pd, y1_pd, y2_pd = GPPredictedData(path_2,num_files)\n",
        "#print(num_files)\n",
        "#print(X_pd_custom)\n",
        "# #### Split the data set for training and testing ###########\n",
        "X_train, X_test, y1_train, y1_test = train_test_split(X_pd, y1_pd,test_size=0.2, random_state= 7)\n",
        "print(X_train)\n",
        "print(X_gt)\n",
        "mae_pd_x, mae_pd_custom_x, mae_gt_x, y1_pred, y1_pred_custom, y1_pred_gt = knnXaxis(X_train, y1_train, X_test,y1_test, y1_gt)\n",
        "#print(y1_test)\n",
        "# print(X_pd)\n",
        "# #### Split the data set for training and testing ###########\n",
        "X_train, X_test, y2_train, y2_test = train_test_split(X_pd, y2_pd,test_size=0.2, random_state= 7)\n",
        "mae_pd_y, mae_pd_custom_y, mae_gt_y, y2_pred, y2_pred_custom, y2_pred_gt =  knnYaxis(X_train, y2_train, X_test, y2_test,y2_gt)\n",
        "#print(y1_test,y2_test)\n",
        "# print(y1_gt.to_frame()['cordX'], y2_gt.to_frame()['cordY'])\n",
        "#y1_y2_gt = pd.concat([y1_gt.to_frame(), y2_gt.to_frame()], axis=1)\n",
        "# print(y1_y2_gt)\n",
        "y1_y2_pd_gt = pd.concat([pd.DataFrame(y1_pred_gt), pd.DataFrame(y2_pred_gt)], axis=1)\n",
        "y1_y2_pd_gt.rename(columns={'0': 'cordX', '0': 'cordY'})\n",
        "# print(pd.DataFrame(y1_pred_gt))\n",
        "# print(y1_y2_pd_gt)\n",
        "# print(pd.concat([y1_y2_gt, y1_y2_pd_gt], axis=1))\n",
        "print(\"---------KNN Localization performance evaluatiion ---------\" )\n",
        "path_3 = floor+'/results'\n",
        "path_4 = floor+'/results'\n",
        "mse_knn_pd = knnLocalizationPredictedData(y1_test, y2_test, X_test, y1_pred, y2_pred, path_3)\n",
        "mse_knn_custom_pd = knnLocalizationcustomPD(y1_pd_custom, y2_pd_custom, X_pd_custom, y1_pred_custom, y2_pred_custom)\n",
        "#mse_knn_gt = knnLocalizationGroundTruthData(y1_gt, y2_gt, X_gt, y1_pred_gt, y2_pred_gt, path_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yQI9g_NxzgnB",
        "outputId": "e189a5eb-5288-4e15-cbcb-149559ca6e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-10-43222634.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-97.7' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  dataframe_gt.fillna('-97.7', inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       IW25030290  IW25030183  IW25030321  IW25030294  IW25030952  IW25030316  \\\n",
            "17776      -102.0     -102.00      -92.39      -102.0     -102.00      -90.17   \n",
            "18342      -102.0     -102.00     -102.00      -102.0     -102.00     -102.00   \n",
            "34174      -102.0      -91.53     -102.00      -102.0      -89.50     -102.00   \n",
            "34758      -102.0      -93.05     -102.00      -102.0      -94.00     -102.00   \n",
            "1101       -102.0     -102.00     -102.00      -102.0     -102.00     -102.00   \n",
            "...           ...         ...         ...         ...         ...         ...   \n",
            "38467      -102.0     -102.00     -102.00      -102.0     -102.00     -102.00   \n",
            "10742      -102.0     -102.00     -102.00      -102.0     -102.00      -92.19   \n",
            "49689      -102.0      -89.37     -102.00      -102.0      -90.98     -102.00   \n",
            "58564      -102.0     -102.00     -102.00      -102.0     -102.00     -102.00   \n",
            "61615      -102.0     -102.00     -102.00      -102.0     -102.00     -102.00   \n",
            "\n",
            "       IW25030298  IW25030303  IW25030283  IW25030182  ...  IW25030304  \\\n",
            "17776      -102.0      -102.0      -102.0     -102.00  ...     -102.00   \n",
            "18342      -102.0      -102.0      -102.0     -102.00  ...     -102.00   \n",
            "34174      -102.0      -102.0      -102.0      -88.62  ...     -102.00   \n",
            "34758      -102.0      -102.0      -102.0      -94.80  ...      -89.96   \n",
            "1101       -102.0      -102.0      -102.0     -102.00  ...     -102.00   \n",
            "...           ...         ...         ...         ...  ...         ...   \n",
            "38467      -102.0      -102.0      -102.0     -102.00  ...      -90.00   \n",
            "10742      -102.0      -102.0      -102.0     -102.00  ...     -102.00   \n",
            "49689      -102.0      -102.0      -102.0      -91.49  ...     -102.00   \n",
            "58564      -102.0      -102.0      -102.0     -102.00  ...     -102.00   \n",
            "61615      -102.0      -102.0      -102.0     -102.00  ...     -102.00   \n",
            "\n",
            "       IW25030310  IW25030277  IW25030308  IW25030185  IW25030312  IW25030289  \\\n",
            "17776      -90.56      -79.67     -102.00     -102.00      -102.0      -102.0   \n",
            "18342      -89.99     -102.00     -102.00     -102.00      -102.0      -102.0   \n",
            "34174     -102.00     -102.00     -102.00     -102.00      -102.0      -102.0   \n",
            "34758      -91.54     -102.00      -93.71     -102.00      -102.0      -102.0   \n",
            "1101      -102.00     -102.00     -102.00     -102.00      -102.0      -102.0   \n",
            "...           ...         ...         ...         ...         ...         ...   \n",
            "38467     -102.00     -102.00     -102.00     -102.00      -102.0      -102.0   \n",
            "10742      -88.43     -102.00     -102.00     -102.00      -102.0      -102.0   \n",
            "49689     -102.00     -102.00     -102.00      -89.37      -102.0      -102.0   \n",
            "58564     -102.00     -102.00     -102.00     -102.00      -102.0      -102.0   \n",
            "61615     -102.00     -102.00     -102.00     -102.00      -102.0      -102.0   \n",
            "\n",
            "       IW25030302  IW25030313  IW25030307  \n",
            "17776      -102.0      -87.04     -102.00  \n",
            "18342      -102.0     -102.00      -90.89  \n",
            "34174      -102.0     -102.00     -102.00  \n",
            "34758      -102.0     -102.00      -89.56  \n",
            "1101       -102.0     -102.00     -102.00  \n",
            "...           ...         ...         ...  \n",
            "38467      -102.0     -102.00     -102.00  \n",
            "10742      -102.0     -102.00     -102.00  \n",
            "49689      -102.0     -102.00     -102.00  \n",
            "58564      -102.0     -102.00     -102.00  \n",
            "61615      -102.0     -102.00     -102.00  \n",
            "\n",
            "[50142 rows x 51 columns]\n",
            "    IW25030290 IW25030183 IW25030321 IW25030294 IW25030952 IW25030316  \\\n",
            "74       -97.7      -97.7      -97.7      -97.7      -97.7      -92.0   \n",
            "67       -97.7      -97.7      -97.7      -97.7      -97.7      -96.0   \n",
            "127      -97.7      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "120      -97.7      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "160      -97.7      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "..         ...        ...        ...        ...        ...        ...   \n",
            "136      -97.7      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "73       -97.7      -97.7      -97.7      -97.7      -97.7 -93.777778   \n",
            "145      -97.7      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "146      -97.7      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "112      -97.7      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "\n",
            "    IW25030298 IW25030303 IW25030283 IW25030182  ... IW25030304 IW25030310  \\\n",
            "74       -97.7      -97.7 -91.264151      -97.7  ...      -97.7      -96.0   \n",
            "67       -97.7      -97.7      -97.7      -97.7  ...      -97.7      -97.7   \n",
            "127      -97.7      -97.7      -97.7      -97.7  ...      -97.7      -97.7   \n",
            "120      -97.7      -97.7      -97.7      -97.7  ...      -97.7      -97.7   \n",
            "160      -97.7      -97.7      -97.7      -97.7  ...      -97.7      -97.7   \n",
            "..         ...        ...        ...        ...  ...        ...        ...   \n",
            "136      -97.7      -97.7      -97.7      -97.7  ...      -97.7      -97.7   \n",
            "73       -97.7      -97.7      -94.2      -97.7  ...      -97.7      -97.7   \n",
            "145      -97.7      -97.7      -97.7      -97.7  ...      -97.7      -97.7   \n",
            "146      -97.7      -97.7      -97.7      -97.7  ...      -97.7      -97.7   \n",
            "112      -97.7      -97.7      -97.7      -97.7  ...      -97.7      -97.7   \n",
            "\n",
            "    IW25030277 IW25030308 IW25030185 IW25030312 IW25030289 IW25030302  \\\n",
            "74  -81.175258      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "67       -97.7      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "127      -97.7      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "120      -97.7      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "160      -97.7      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "..         ...        ...        ...        ...        ...        ...   \n",
            "136 -93.360465      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "73  -60.122137      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "145      -97.7      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "146      -97.7      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "112      -97.7      -97.7      -97.7      -97.7      -97.7      -97.7   \n",
            "\n",
            "    IW25030313 IW25030307  \n",
            "74       -97.0      -97.7  \n",
            "67     -92.375      -97.7  \n",
            "127      -92.0      -97.7  \n",
            "120      -97.7      -97.7  \n",
            "160      -97.7      -97.7  \n",
            "..         ...        ...  \n",
            "136      -97.7      -97.7  \n",
            "73       -97.7      -97.7  \n",
            "145      -97.7      -97.7  \n",
            "146      -97.7      -97.7  \n",
            "112      -97.7      -97.7  \n",
            "\n",
            "[161 rows x 51 columns]\n",
            "---------KNN training for X-axis result---------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y1_pred' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-10-43222634.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m \u001b[0mmae_pd_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae_pd_custom_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae_gt_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_pred_custom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_pred_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknnXaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;31m#print(y1_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;31m# print(X_pd)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-10-43222634.py\u001b[0m in \u001b[0;36mknnXaxis\u001b[0;34m(X_train, y1_train, X_test, y1_test, y1_gt)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# knn_accuracy=accuracy_score(y1_test, y1_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# print('\\nThe Models Accuracy is', knn_accuracy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mMAE1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0mMAE2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1_pred_custom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1_pd_custom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted data knn-mae-X-axis :\\t\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAE1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.305\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y1_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Localization_3 (for path estimation)"
      ],
      "metadata": {
        "id": "p-DVh_pvfZoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "import os\n",
        "from IPython.display import display\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C,WhiteKernel , RationalQuadratic ,ExpSineSquared\n",
        "# %matplotlib notebook\n",
        "\n",
        "\n",
        "\n",
        "def GPPredictedData(directory_pd, num_files):\n",
        "    dataframes_pd = []\n",
        "    for filename in os.listdir(directory_pd):\n",
        "        file_path = os.path.join(directory_pd, filename)\n",
        "        # Read CSV file\n",
        "        df = pd.read_csv(file_path)\n",
        "        # Rename column\n",
        "        df.rename(columns={'rssi_mean': filename.split('.csv')[0]}, inplace=True)\n",
        "        # Drop 'rssi_std' column\n",
        "        df = df.drop(['rssi_std'], axis=1)\n",
        "        # Append dataframe to the list\n",
        "        dataframes_pd.append(df)\n",
        "    # Merge all dataframes on 'location'\n",
        "    dataframes_pd = pd.concat([df.set_index('location') for df in dataframes_pd], axis=1, join='inner').reset_index()\n",
        "    new = dataframes_pd.location.str.split(\",\", n = -1, expand = True)\n",
        "    dataframes_pd['cordX'] = new[0].astype(int)\n",
        "    dataframes_pd['cordY'] = new[1].astype(int)\n",
        "    X_pd = dataframes_pd.iloc[:, 1:num_files]  # Adjusted slice to include all device columns (assuming num_files is the count of device columns)\n",
        "    y1_pd = dataframes_pd['cordX']\n",
        "    y2_pd = dataframes_pd['cordY']\n",
        "\n",
        "    # Sort the columns of X_pd in ascending order (alphabetical order of device names)\n",
        "    sorted_columns = sorted(X_pd.columns)\n",
        "    X_pd = X_pd[sorted_columns]\n",
        "\n",
        "    dataframes_pd.head()\n",
        "    dataframes_pd.shape\n",
        "\n",
        "    return X_pd, y1_pd, y2_pd\n",
        "\n",
        "\n",
        "\n",
        "def ContinuousData(num_files):\n",
        "    dataframes_pd = []\n",
        "    file_path = '/content/filled_Ground_A-block.csv'\n",
        "        # Read CSV file\n",
        "    dataframes_pd = pd.read_csv(file_path)\n",
        "        # Rename column\n",
        "\n",
        "    # Merge all dataframes on 'location'\n",
        "    #dataframes_pd = pd.concat([df.set_index('location') for df in dataframes_pd], axis=1, join='inner').reset_index()\n",
        "    new = dataframes_pd.location.str.split(\",\", n = -1, expand = True)\n",
        "    dataframes_pd['cordX'] = new[0].astype(int)\n",
        "    dataframes_pd['cordY'] = new[1].astype(int)\n",
        "    X_cd = dataframes_pd.iloc[:, 1:num_files]\n",
        "    y1_cd = dataframes_pd['cordX']\n",
        "    y2_cd = dataframes_pd['cordY']\n",
        "\n",
        "    dataframes_pd.head()\n",
        "    dataframes_pd.shape\n",
        "\n",
        "    return X_cd, y1_cd, y2_cd\n",
        "\n",
        "\n",
        "path_2 = '/content/Localization_project-main/Ground/beacons_pd'\n",
        "num_files = len(os.listdir(path_2))+1    # Count the number of files\n",
        "X_cd, y1_cd, y2_cd = ContinuousData(num_files)\n",
        "X_pd, y1_pd, y2_pd = GPPredictedData(path_2,num_files)\n",
        "\n",
        "X_train, X_test, y1_train, y1_test = train_test_split(X_pd, y1_pd,test_size=0.2, random_state= 7)\n",
        "# print(X_train)\n",
        "# print(X_cd)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors = 3)\n",
        "knn_classifier.fit(X_train, y1_train.values.ravel())\n",
        "y1_pred=knn_classifier.predict(X_cd)\n",
        "X_train, X_test, y2_train, y2_test = train_test_split(X_pd, y2_pd,test_size=0.2, random_state= 7)\n",
        "knn_classifier.fit(X_train, y2_train.values.ravel())\n",
        "y2_pred=knn_classifier.predict(X_cd)\n",
        "print(y1_pred)\n",
        "print(y2_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9wgMSZ2fbfw",
        "outputId": "89dfac48-981c-4075-bca5-b41f1f3f0afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[37 49 31 37 90 77 77 90 77 77 54 77 89 89 89 59 77 77 89 77 40 89 83 77\n",
            " 40 77 89 83 58 30]\n",
            "[82 73 82 82 79 52 52 79 52 52 71 52 73 73 73 69 52 52 73 52 79 73 72 52\n",
            " 79 52 73 72 70 79]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For plotting path"
      ],
      "metadata": {
        "id": "5uc6SkUTaQT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Given coordinates\n",
        "x = [37, 49, 31, 37, 90, 77, 77, 90, 77, 77, 54, 77, 89, 89, 89, 59, 77, 77, 89, 77, 40, 89, 83, 77, 40, 77, 89, 83, 58, 30]\n",
        "y = [82, 73, 82, 82, 79, 52, 52, 79, 52, 52, 71, 52, 73, 73, 73, 69, 52, 52, 73, 52, 79, 73, 72, 52, 79, 52, 73, 72, 70, 79]\n",
        "\n",
        "# Create plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.scatter(x, y, c='blue', s=100, alpha=0.7, edgecolors='w', linewidth=2)\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Coordinate Points Plot', fontsize=16)\n",
        "plt.xlabel('X Coordinates', fontsize=14)\n",
        "plt.ylabel('Y Coordinates', fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Add point labels\n",
        "for i, (xi, yi) in enumerate(zip(x, y)):\n",
        "    plt.annotate(f'P{i+1}', (xi, yi), xytext=(5, 5),\n",
        "                 textcoords='offset points', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yS799VF9aUHU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}